{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 MINST数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Training data size:  55000\n",
      "Validating data size:  5000\n",
      "Testing data size:  10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../datasets/MNIST_data/\", one_hot=True)\n",
    "print(\"Training data size: \", mnist.train.num_examples)\n",
    "print(\"Validating data size: \", mnist.validation.num_examples)\n",
    "print(\"Testing data size: \", mnist.test.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 使用MINST数据训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784     # 输入节点\n",
    "OUTPUT_NODE = 10     # 输出节点\n",
    "LAYER1_NODE = 500    # 隐藏层数       \n",
    "                              \n",
    "BATCH_SIZE = 100     # 每次batch打包的样本个数        \n",
    "\n",
    "# 模型相关的参数\n",
    "LEARNING_RATE_BASE = 0.8      \n",
    "LEARNING_RATE_DECAY = 0.99    \n",
    "REGULARAZTION_RATE = 0.0001   \n",
    "TRAINING_STEPS = 30000        \n",
    "MOVING_AVERAGE_DECAY = 0.99  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 计算神经网络前向传播结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, weights1, biases1, weights2, biases2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, weights1) + biases1 ) \n",
    "        return tf.matmul(layer1, weights2) + biases2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor, avg_class.average(weights1)) + avg_class.average(biases1))\n",
    "        return tf.matmul(layer1, avg_class.average(weights2)) + avg_class.average(biases2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(minst):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name='y-input')\n",
    "    \n",
    "    #生成隐藏层参数\n",
    "    weights1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    \n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    # 计算不含滑动平均类的前向传播结果\n",
    "    y = inference(x, None, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 定义训练轮数及相关的滑动平均类\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    varible_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    varible_averages_op = varible_averages.apply(tf.trainable_variables())\n",
    "    average_y = inference(x, varible_averages, weights1, biases1, weights2, biases2)\n",
    "    \n",
    "    # 计算交叉熵及其平均值\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    #带有l2正则的损失函数\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n",
    "    regularization = regularizer(weights1) + regularizer(weights2)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    learning_ratge = tf.train.exponential_decay(LEARNING_RATE_BASE,\n",
    "                                               global_step,\n",
    "                                               minst.train.num_examples / BATCH_SIZE,#过完一遍数据需要的迭代次数\n",
    "                                               LEARNING_RATE_DECAY)#学习率衰减速度\n",
    "    \n",
    "    #优化目标\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_ratge).minimize(loss, global_step=global_step)\n",
    "\n",
    "    #每次迭代需要更新权重和权重对应的滑动平均值，为了一次完成多个操作\n",
    "    with tf.control_dependencies([train_step, varible_averages_op]):\n",
    "        train_op = tf.no_op(name='train')\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))           \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        validate_feed = {x: minst.validation.images,\n",
    "                         y_: minst.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels} \n",
    "\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g \" % (i, validate_acc))\n",
    "\n",
    "            xs,ys=mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={x:xs,y_:ys})\n",
    "\n",
    "        test_acc=sess.run(accuracy,feed_dict=test_feed)\n",
    "        print((\"After %d training step(s), test accuracy using average model is %g\" %(TRAINING_STEPS, test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.1168 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.979 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.9812 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.9828 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9834 \n",
      "After 5000 training step(s), validation accuracy using average model is 0.9834 \n",
      "After 6000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 7000 training step(s), validation accuracy using average model is 0.9834 \n",
      "After 8000 training step(s), validation accuracy using average model is 0.9834 \n",
      "After 9000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 10000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 11000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 12000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 13000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 14000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 15000 training step(s), validation accuracy using average model is 0.984 \n",
      "After 16000 training step(s), validation accuracy using average model is 0.9842 \n",
      "After 17000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 18000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 19000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 20000 training step(s), validation accuracy using average model is 0.9852 \n",
      "After 21000 training step(s), validation accuracy using average model is 0.9854 \n",
      "After 22000 training step(s), validation accuracy using average model is 0.9846 \n",
      "After 23000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 24000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 25000 training step(s), validation accuracy using average model is 0.985 \n",
      "After 26000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 27000 training step(s), validation accuracy using average model is 0.9844 \n",
      "After 28000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 29000 training step(s), validation accuracy using average model is 0.9848 \n",
      "After 30000 training step(s), test accuracy using average model is 0.9833\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../datasets/MNIST_data\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
